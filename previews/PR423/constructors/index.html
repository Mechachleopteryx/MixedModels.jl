<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Model constructors · MixedModels</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="MixedModels logo"/></a><div class="docs-package-name"><span class="docs-autofit">MixedModels</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">MixedModels.jl Documentation</a></li><li class="is-active"><a class="tocitem" href>Model constructors</a><ul class="internal"><li><a class="tocitem" href="#Examples-of-linear-mixed-effects-model-fits"><span>Examples of linear mixed-effects model fits</span></a></li></ul></li><li><a class="tocitem" href="../optimization/">Details of the parameter estimation</a></li><li><a class="tocitem" href="../GaussHermite/">Normalized Gauss-Hermite Quadrature</a></li><li><a class="tocitem" href="../bootstrap/">Parametric bootstrap for linear mixed-effects models</a></li><li><a class="tocitem" href="../rankdeficiency/">Rank deficiency in mixed-effects models</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Model constructors</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Model constructors</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaStats/MixedModels.jl/blob/master/docs/src/constructors.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Model-constructors"><a class="docs-heading-anchor" href="#Model-constructors">Model constructors</a><a id="Model-constructors-1"></a><a class="docs-heading-anchor-permalink" href="#Model-constructors" title="Permalink"></a></h1><p>The <code>LinearMixedModel</code> type represents a linear mixed-effects model. Typically it is constructed from a <code>Formula</code> and an appropriate <code>Table</code> type, usually a <code>DataFrame</code>.</p><article class="docstring"><header><a class="docstring-binding" id="MixedModels.LinearMixedModel" href="#MixedModels.LinearMixedModel"><code>MixedModels.LinearMixedModel</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinearMixedModel</code></pre><p>Linear mixed-effects model representation</p><p><strong>Fields</strong></p><ul><li><code>formula</code>: the formula for the model</li><li><code>allterms</code>: a vector of random-effects terms, the fixed-effects terms and the response</li><li><code>reterms</code>: a <code>Vector{AbstractReMat{T}}</code> of random-effects terms.</li><li><code>feterms</code>: a <code>Vector{FeMat{T}}</code> of the fixed-effects model matrix and the response</li><li><code>sqrtwts</code>: vector of square roots of the case weights.  Can be empty.</li><li><code>parmap</code> : Vector{NTuple{3,Int}} of (block, row, column) mapping of θ to λ</li><li><code>dims</code> : NamedTuple{(:n, :p, :nretrms),NTuple{3,Int}} of dimensions.  <code>p</code> is the rank of <code>X</code>, which may be smaller than <code>size(X, 2)</code>.</li><li><code>A</code>: an <code>nt × nt</code> symmetric <code>BlockMatrix</code> of matrices representing <code>hcat(Z,X,y)&#39;hcat(Z,X,y)</code></li><li><code>L</code>: a <code>nt × nt</code> <code>BlockMatrix</code> - the lower Cholesky factor of <code>Λ&#39;AΛ+I</code></li><li><code>optsum</code>: an <a href="../optimization/#MixedModels.OptSummary"><code>OptSummary</code></a> object</li></ul><p><strong>Properties</strong></p><ul><li><code>θ</code> or <code>theta</code>: the covariance parameter vector used to form λ</li><li><code>β</code> or <code>beta</code>: the fixed-effects coefficient vector</li><li><code>λ</code> or <code>lambda</code>: a vector of lower triangular matrices repeated on the diagonal blocks of <code>Λ</code></li><li><code>σ</code> or <code>sigma</code>: current value of the standard deviation of the per-observation noise</li><li><code>b</code>: random effects on the original scale, as a vector of matrices</li><li><code>u</code>: random effects on the orthogonal scale, as a vector of matrices</li><li><code>lowerbd</code>: lower bounds on the elements of θ</li><li><code>X</code>: the fixed-effects model matrix</li><li><code>y</code>: the response vector</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/f1dea3fea661b57b67716edc052f70f6eeeff92a/src/linearmixedmodel.jl#L1-L30">source</a></section></article><h2 id="Examples-of-linear-mixed-effects-model-fits"><a class="docs-heading-anchor" href="#Examples-of-linear-mixed-effects-model-fits">Examples of linear mixed-effects model fits</a><a id="Examples-of-linear-mixed-effects-model-fits-1"></a><a class="docs-heading-anchor-permalink" href="#Examples-of-linear-mixed-effects-model-fits" title="Permalink"></a></h2><p>For illustration, several data sets from the <em>lme4</em> package for <em>R</em> are made available in <code>.arrow</code> format in this package. Often, for convenience, we will convert these to <code>DataFrame</code>s. These data sets include the <code>dyestuff</code> and <code>dyestuff2</code> data sets.</p><article class="docstring"><header><a class="docstring-binding" id="MixedModels.dataset" href="#MixedModels.dataset"><code>MixedModels.dataset</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">dataset(nm)</code></pre><p>Return, as an <code>Arrow.Table</code>, the test data set named <code>nm</code>, which can be a <code>String</code> or <code>Symbol</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaStats/MixedModels.jl/blob/f1dea3fea661b57b67716edc052f70f6eeeff92a/src/utilities.jl#L142-L146">source</a></section></article><pre><code class="language-julia">using DataFrames, MixedModels
using StatsBase: describe
dyestuff = DataFrame(MixedModels.dataset(:dyestuff))
describe(dyestuff)</code></pre><table class="data-frame"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Nothing</th><th>DataType</th></tr></thead><tbody><p>2 rows × 8 columns</p><tr><th>1</th><td>batch</td><td></td><td>A</td><td></td><td>F</td><td>6</td><td></td><td>String</td></tr><tr><th>2</th><td>yield</td><td>1527.5</td><td>1440</td><td>1530.0</td><td>1635</td><td></td><td></td><td>Int16</td></tr></tbody></table><h3 id="Models-with-simple,-scalar-random-effects"><a class="docs-heading-anchor" href="#Models-with-simple,-scalar-random-effects">Models with simple, scalar random effects</a><a id="Models-with-simple,-scalar-random-effects-1"></a><a class="docs-heading-anchor-permalink" href="#Models-with-simple,-scalar-random-effects" title="Permalink"></a></h3><p>The formula language in <em>Julia</em> is similar to that in <em>R</em> which is based on (Wilkinson and Rogers <a href="https://dx.doi.org/10.2307/2346786">1973</a>). In Julia a formula must be enclosed in a call to the <code>@formula</code> macro.</p><article class="docstring"><header><a class="docstring-binding" id="StatsModels.@formula" href="#StatsModels.@formula"><code>StatsModels.@formula</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia">@formula(ex)</code></pre><p>Capture and parse a formula expression as a <code>Formula</code> struct.</p><p>A formula is an abstract specification of a dependence between <em>left-hand</em> and <em>right-hand</em> side variables as in, e.g., a regression model.  Each side specifies at a high level how tabular data is to be converted to a numerical matrix suitable for modeling.  This specification looks something like Julia code, is represented as a Julia <code>Expr</code>, but uses special syntax.  The <code>@formula</code> macro takes an expression like <code>y ~ 1 + a*b</code>, transforms it according to the formula syntax rules into a lowered form (like <code>y ~ 1 + a + b + a&amp;b</code>), and constructs a <code>Formula</code> struct which captures the original expression, the lowered expression, and the left- and right-hand-side.</p><p>Operators that have special interpretations in this syntax are</p><ul><li><code>~</code> is the formula separator, where it is a binary operator (the first argument is the left-hand side, and the second is the right-hand side.</li><li><code>+</code> concatenates variables as columns when generating a model matrix.</li><li><code>&amp;</code> representes an <em>interaction</em> between two or more variables, which corresponds to a row-wise kronecker product of the individual terms (or element-wise product if all terms involved are continuous/scalar).</li><li><code>*</code> expands to all main effects and interactions: <code>a*b</code> is equivalent to <code>a+b+a&amp;b</code>, <code>a*b*c</code> to <code>a+b+c+a&amp;b+a&amp;c+b&amp;c+a&amp;b&amp;c</code>, etc.</li><li><code>1</code>, <code>0</code>, and <code>-1</code> indicate the presence (for <code>1</code>) or absence (for <code>0</code> and <code>-1</code>) of an intercept column.</li></ul><p>The rules that are applied are</p><ul><li>The associative rule (un-nests nested calls to <code>+</code>, <code>&amp;</code>, and <code>*</code>).</li><li>The distributive rule (interactions <code>&amp;</code> distribute over concatenation <code>+</code>).</li><li>The <code>*</code> rule expands <code>a*b</code> to <code>a+b+a&amp;b</code> (recursively).</li><li>Subtraction is converted to addition and negation, so <code>x-1</code> becomes <code>x + -1</code> (applies only to subtraction of literal 1).</li><li>Single-argument <code>&amp;</code> calls are stripped, so <code>&amp;(x)</code> becomes the main effect <code>x</code>.</li></ul></div></section></article><p>A basic model with simple, scalar random effects for the levels of <code>batch</code> (the batch of an intermediate product, in this case) is declared and fit as</p><pre><code class="language-julia">fm = @formula(yield ~ 1 + (1|batch))
fm1 = fit(MixedModel, fm, dyestuff)</code></pre><pre class="documenter-example-output">Linear mixed model fit by maximum likelihood
 yield ~ 1 + (1 | batch)
   logLik   -2 logLik     AIC       AICc        BIC    
  -163.6635   327.3271   333.3271   334.2501   337.5307

Variance components:
            Column   VarianceStd.Dev.
batch    (Intercept)  1388.33 37.2603
Residual              2451.25 49.5101
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
────────────────────────────────────────────────
              Coef.  Std. Error      z  Pr(&gt;|z|)
────────────────────────────────────────────────
(Intercept)  1527.5     17.6946  86.33    &lt;1e-99
────────────────────────────────────────────────</pre><p>(If you are new to Julia you may find that this first fit takes an unexpectedly long time, due to Just-In-Time (JIT) compilation of the code. The subsequent calls to such functions are much faster.)</p><pre><code class="language-julia">using BenchmarkTools
dyestuff2 = MixedModels.dataset(:dyestuff2)
@benchmark fit(MixedModel, $fm, $dyestuff2)</code></pre><pre class="documenter-example-output">BenchmarkTools.Trial: 
  memory estimate:  81.41 KiB
  allocs estimate:  1461
  --------------
  minimum time:     363.728 μs (0.00% GC)
  median time:      440.434 μs (0.00% GC)
  mean time:        473.818 μs (6.11% GC)
  maximum time:     28.366 ms (94.59% GC)
  --------------
  samples:          10000
  evals/sample:     1</pre><p>By default, the model is fit by maximum likelihood. To use the <code>REML</code> criterion instead, add the optional named argument <code>REML=true</code> to the call to <code>fit</code></p><pre><code class="language-julia">fm1reml = fit(MixedModel, fm, dyestuff, REML=true)</code></pre><pre class="documenter-example-output">Linear mixed model fit by REML
 yield ~ 1 + (1 | batch)
 REML criterion at convergence: 319.6542768422538

Variance components:
            Column   VarianceStd.Dev.
batch    (Intercept)  1764.05 42.0006
Residual              2451.25 49.5101
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
────────────────────────────────────────────────
              Coef.  Std. Error      z  Pr(&gt;|z|)
────────────────────────────────────────────────
(Intercept)  1527.5     19.3834  78.80    &lt;1e-99
────────────────────────────────────────────────</pre><h3 id="Float-point-type-in-the-model"><a class="docs-heading-anchor" href="#Float-point-type-in-the-model">Float-point type in the model</a><a id="Float-point-type-in-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Float-point-type-in-the-model" title="Permalink"></a></h3><p>The type of <code>fm1</code></p><pre><code class="language-julia">typeof(fm1)</code></pre><pre class="documenter-example-output">LinearMixedModel{Float64}</pre><p>includes the floating point type used internally for the various matrices, vectors, etc. that represent the model. At present, this will always be <code>Float64</code> because the parameter estimates are optimized using the <a href="https://github.com/JuliaOpt/NLopt.jl"><code>NLopt</code> package</a> which calls compiled C code that only allows for optimization with respect to a <code>Float64</code> parameter vector.</p><p>So in theory other floating point types, such as <code>BigFloat</code> or <code>Float32</code>, can be used to define a model but in practice only <code>Float64</code> works at present.</p><blockquote><p>In theory, theory and practice are the same.  In practice, they aren&#39;t.  – Anon</p></blockquote><h3 id="Simple,-scalar-random-effects"><a class="docs-heading-anchor" href="#Simple,-scalar-random-effects">Simple, scalar random effects</a><a id="Simple,-scalar-random-effects-1"></a><a class="docs-heading-anchor-permalink" href="#Simple,-scalar-random-effects" title="Permalink"></a></h3><p>A simple, scalar random effects term in a mixed-effects model formula is of the form <code>(1|G)</code>. All random effects terms end with <code>|G</code> where <code>G</code> is the <em>grouping factor</em> for the random effect. The name or, more generally, the expression <code>G</code> should evaluate to a categorical array that has a distinct set of <em>levels</em>. The random effects are associated with the levels of the grouping factor.</p><p>A <em>scalar</em> random effect is, as the name implies, one scalar value for each level of the grouping factor. A <em>simple, scalar</em> random effects term is of the form, <code>(1|G)</code>. It corresponds to a shift in the intercept for each level of the grouping factor.</p><h3 id="Models-with-vector-valued-random-effects"><a class="docs-heading-anchor" href="#Models-with-vector-valued-random-effects">Models with vector-valued random effects</a><a id="Models-with-vector-valued-random-effects-1"></a><a class="docs-heading-anchor-permalink" href="#Models-with-vector-valued-random-effects" title="Permalink"></a></h3><p>The <em>sleepstudy</em> data are observations of reaction time, <code>reaction</code>, on several subjects, <code>subj</code>, after 0 to 9 days of sleep deprivation, <code>days</code>. A model with random intercepts and random slopes for each subject, allowing for within-subject correlation of the slope and intercept, is fit as</p><pre><code class="language-julia">sleepstudy = MixedModels.dataset(:sleepstudy)
fm2 = fit(MixedModel, @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy)</code></pre><pre class="documenter-example-output">Linear mixed model fit by maximum likelihood
 reaction ~ 1 + days + (1 + days | subj)
   logLik   -2 logLik     AIC       AICc        BIC    
  -875.9697  1751.9393  1763.9393  1764.4249  1783.0971

Variance components:
            Column   Variance Std.Dev.   Corr.
subj     (Intercept)  565.5107 23.78047
         days          32.6821  5.71683 +0.08
Residual              654.9414 25.59182
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
──────────────────────────────────────────────────
                Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────
(Intercept)  251.405      6.63226  37.91    &lt;1e-99
days          10.4673     1.50224   6.97    &lt;1e-11
──────────────────────────────────────────────────</pre><h3 id="Models-with-multiple,-scalar-random-effects-terms"><a class="docs-heading-anchor" href="#Models-with-multiple,-scalar-random-effects-terms">Models with multiple, scalar random-effects terms</a><a id="Models-with-multiple,-scalar-random-effects-terms-1"></a><a class="docs-heading-anchor-permalink" href="#Models-with-multiple,-scalar-random-effects-terms" title="Permalink"></a></h3><p>A model for the <em>Penicillin</em> data incorporates random effects for the plate, and for the sample. As every sample is used on every plate these two factors are <em>crossed</em>.</p><pre><code class="language-julia">penicillin = MixedModels.dataset(:penicillin)
fm3 = fit(MixedModel, @formula(diameter ~ 1 + (1|plate) + (1|sample)), penicillin)</code></pre><pre class="documenter-example-output">Linear mixed model fit by maximum likelihood
 diameter ~ 1 + (1 | plate) + (1 | sample)
   logLik   -2 logLik     AIC       AICc        BIC    
  -166.0942   332.1883   340.1883   340.4761   352.0676

Variance components:
            Column   Variance Std.Dev. 
plate    (Intercept)  0.714979 0.845565
sample   (Intercept)  3.135193 1.770648
Residual              0.302426 0.549933
 Number of obs: 144; levels of grouping factors: 24, 6

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  22.9722    0.744596  30.85    &lt;1e-99
─────────────────────────────────────────────────</pre><p>In contrast, the <code>cask</code> grouping factor is <em>nested</em> within the <code>batch</code> grouping factor in the <em>Pastes</em> data.</p><pre><code class="language-julia">pastes = DataFrame(MixedModels.dataset(:pastes))
describe(pastes)</code></pre><table class="data-frame"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Nothing</th><th>DataType</th></tr></thead><tbody><p>3 rows × 8 columns</p><tr><th>1</th><td>batch</td><td></td><td>A</td><td></td><td>J</td><td>10</td><td></td><td>String</td></tr><tr><th>2</th><td>cask</td><td></td><td>a</td><td></td><td>c</td><td>3</td><td></td><td>String</td></tr><tr><th>3</th><td>strength</td><td>60.0533</td><td>54.2</td><td>59.3</td><td>66.0</td><td></td><td></td><td>Float64</td></tr></tbody></table><p>This can be expressed using the solidus (the &quot;<code>/</code>&quot; character) to separate grouping factors, read &quot;<code>cask</code> nested within <code>batch</code>&quot;:</p><pre><code class="language-julia">fm4a = fit(MixedModel, @formula(strength ~ 1 + (1|batch/cask)), pastes)</code></pre><pre class="documenter-example-output">Linear mixed model fit by maximum likelihood
 strength ~ 1 + (1 | batch) + (1 | batch &amp; cask)
   logLik   -2 logLik     AIC       AICc        BIC    
  -123.9972   247.9945   255.9945   256.7217   264.3718

Variance components:
                Column   Variance Std.Dev. 
batch &amp; cask (Intercept)  8.433616 2.904069
batch        (Intercept)  1.199180 1.095071
Residual                  0.678002 0.823409
 Number of obs: 60; levels of grouping factors: 30, 10

  Fixed-effects parameters:
─────────────────────────────────────────────────
               Coef.  Std. Error      z  Pr(&gt;|z|)
─────────────────────────────────────────────────
(Intercept)  60.0533    0.642136  93.52    &lt;1e-99
─────────────────────────────────────────────────</pre><p>If the levels of the inner grouping factor are unique across the levels of the outer grouping factor, then this nesting does not need to expressed explicitly in the model syntax. For example, defining <code>sample</code> to be the combination of <code>batch</code> and <code>cask</code>, yields a naming scheme where the nesting is apparent from the data even if not expressed in the formula. (That is, each level of <code>sample</code> occurs in conjunction with only one level of <code>batch</code>.) As such, this model is equivalent to the previous one.</p><pre><code class="language-">pastes.sample = (string.(pastes.cask, &quot;&amp;&quot;,  pastes.batch))
fm4b - fit(MixedModel, @formula(strength ~ 1 + (1|sample) + (1|batch)), pastes)</code></pre><p>@example Main insteval = MixedModels.dataset(:insteval) fm5 = fit(MixedModel, @formula(y ~ 1 + service * dept + (1|s) + (1|d)), insteval)</p><pre><code class="language-none"></code></pre><p>@setup Main @testset &quot;fm5&quot; begin     @test deviance(fm5) ≈ 2.37585553e5     @test varest(fm5) ≈ 1.38472777 atol = 1e-6     @test VarCorr(fm5).σρ.s.σ[1] ≈ 0.32468136 rtol = 6     @test VarCorr(fm5).σρ.d.σ[1] ≈ 0.50834669 rtol = 6 end</p><pre><code class="language-none">
### Simplifying the random effect correlation structure

MixedEffects.jl estimates not only the *variance* of the effects for each random effect level, but also the *correlation* between the random effects for different predictors.
So, for the model of the *sleepstudy* data above, one of the parameters that is estimated is the correlation between each subject&#39;s random intercept (i.e., their baseline reaction time) and slope (i.e., their particular change in reaction time per day of sleep deprivation).
In some cases, you may wish to simplify the random effects structure by removing these correlation parameters.
This often arises when there are many random effects you want to estimate (as is common in psychological experiments with many conditions and covariates), since the number of random effects parameters increases as the square of the number of predictors, making these models difficult to estimate from limited data.

The special syntax `zerocorr` can be applied to individual random effects terms inside the `@formula`:</code></pre><p>@example Main fm2zerocorr_fm = fit(MixedModel, @formula(reaction ~ 1 + days + zerocorr(1 + days|subj)), sleepstudy)</p><pre><code class="language-none">
Alternatively, correlations between parameters can be removed by including them as separate random effects terms:</code></pre><p>@example Main fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj) + (days|subj)), sleepstudy)</p><pre><code class="language-none">
Finally, for predictors that are categorical, MixedModels.jl will estimate correlations between each level.
Notice the large number of correlation parameters if we treat `days` as a categorical variable by giving it contrasts:</code></pre><p>@example Main fit(MixedModel, @formula(reaction ~ 1 + days + (1 + days|subj)), sleepstudy,     contrasts = Dict(:days =&gt; DummyCoding()))</p><pre><code class="language-none">
Separating the `1` and `days` random effects into separate terms removes the correlations between the intercept and the levels of `days`, but not between the levels themselves:</code></pre><p>@example Main fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj) + (days|subj)), sleepstudy,     contrasts = Dict(:days =&gt; DummyCoding()))</p><pre><code class="language-none">(Notice that the variance component for `days: 1` is estimated as zero, so the correlations for this component are undefined and expressed as `NaN`, not a number.)

An alternative is to force all the levels of `days` as indicators using `fulldummy` encoding.</code></pre><p>@docs fulldummy</p><pre><code class="language-none"></code></pre><p>@example Main fit(MixedModel, @formula(reaction ~ 1 + days + (1 + fulldummy(days)|subj)), sleepstudy,     contrasts = Dict(:days =&gt; DummyCoding()))</p><pre><code class="language-none">This fit produces a better fit as measured by the objective (negative twice the log-likelihood is 1610.8) but at the expense of adding many more parameters to the model.
As a result, model comparison criteria such, as `AIC` and `BIC`, are inflated.

But using `zerocorr` on the individual terms does remove the correlations between the levels:</code></pre><p>@example Main fit(MixedModel, @formula(reaction ~ 1 + days + zerocorr(1 + days|subj)), sleepstudy,     contrasts = Dict(:days =&gt; DummyCoding()))</p><pre><code class="language-none"></code></pre><p>@example Main fit(MixedModel, @formula(reaction ~ 1 + days + (1|subj) + zerocorr(days|subj)), sleepstudy,     contrasts = Dict(:days =&gt; DummyCoding()))</p><pre><code class="language-none"></code></pre><p>@example Main fit(MixedModel, @formula(reaction ~ 1 + days + zerocorr(1 + fulldummy(days)|subj)), sleepstudy,     contrasts = Dict(:days =&gt; DummyCoding()))</p><pre><code class="language-none">
## Fitting generalized linear mixed models

To create a GLMM representation</code></pre><p>@docs GeneralizedLinearMixedModel</p><pre><code class="language-none">the distribution family for the response, and possibly the link function, must be specified.
</code></pre><p>@example Main verbagg = MixedModels.dataset(:verbagg) verbaggform = @formula(r2 ~ 1 + anger + gender + btype + situ + mode + (1|subj) + (1|item)); gm1 = fit(MixedModel, verbaggform, verbagg, Bernoulli())</p><pre><code class="language-none">
The canonical link, which is `LogitLink` for the `Bernoulli` distribution, is used if no explicit link is specified.

Note that, in keeping with convention in the [`GLM` package](https://github.com/JuliaStats/GLM.jl), the distribution family for a binary (i.e. 0/1) response is the `Bernoulli` distribution.
The `Binomial` distribution is only used when the response is the fraction of trials returning a positive, in which case the number of trials must be specified as the case weights.

### Optional arguments to fit

An alternative approach is to create the `GeneralizedLinearMixedModel` object then call `fit!` on it.
The optional arguments `fast` and/or `nAGQ` can be passed to the optimization process via both `fit` and `fit!` (i.e these optimization settings are not used nor recognized when constructing the model).

As the name implies, `fast=true`, provides a faster but somewhat less accurate fit.
These fits may suffice for model comparisons.</code></pre><p>@example Main gm1a = fit(MixedModel, verbaggform, verbagg, Bernoulli(), fast = true) deviance(gm1a) - deviance(gm1) @benchmark fit(MixedModel, verbaggform, verbagg, Bernoulli()) @benchmark fit(MixedModel, verbaggform, verbagg, Bernoulli(), fast = true)</p><pre><code class="language-none">
The optional argument `nAGQ=k` causes evaluation of the deviance function to use a `k` point
adaptive Gauss-Hermite quadrature rule.
This method only applies to models with a single, simple, scalar random-effects term, such as</code></pre><p>@example Main contraception = MixedModels.dataset(:contra) contraform = @formula(use ~ 1 + age + abs2(age) + livch + urban + (1|dist)); bernoulli = Bernoulli() deviances = Dict{Symbol,Float64}() b = @benchmarkable deviances[:default] = deviance(fit(MixedModel, contraform, contraception, bernoulli)); run(b) b = @benchmarkable deviances[:fast] = deviance(fit(MixedModel, contraform, contraception, bernoulli, fast = true)); run(b) b = @benchmarkable deviances[:nAGQ] = deviance(fit(MixedModel, contraform, contraception, bernoulli, nAGQ=9)); run(b) b = @benchmarkable deviances[:nAGQ_fast] = deviance(fit(MixedModel, contraform, contraception, bernoulli, nAGQ=9, fast=true)); run(b) sort(deviances)</p><pre><code class="language-none">
# Extractor functions

`LinearMixedModel` and `GeneralizedLinearMixedModel` are subtypes of `StatsBase.RegressionModel` which, in turn, is a subtype of `StatsBase.StatisticalModel`.
Many of the generic extractors defined in the `StatsBase` package have methods for these models.

## Model-fit statistics

The statistics describing the quality of the model fit include</code></pre><p>@docs loglikelihood(::StatisticalModel) aic bic dof(::StatisticalModel) nobs(::StatisticalModel)</p><pre><code class="language-none"></code></pre><p>@example Main loglikelihood(fm1)</p><pre><code class="language-none"></code></pre><p>@example Main aic(fm1)</p><pre><code class="language-none"></code></pre><p>@example Main bic(fm1)</p><pre><code class="language-none"></code></pre><p>@example Main dof(fm1)   # 1 fixed effect, 2 variances</p><pre><code class="language-none"></code></pre><p>@example Main nobs(fm1)  # 30 observations</p><pre><code class="language-none"></code></pre><p>@example Main loglikelihood(gm1)</p><pre><code class="language-none">
In general the [`deviance`](https://en.wikipedia.org/wiki/Deviance_(statistics)) of a statistical model fit is negative twice the log-likelihood adjusting for the saturated model.</code></pre><p>@docs deviance(::StatisticalModel)</p><pre><code class="language-none">
Because it is not clear what the saturated model corresponding to a particular `LinearMixedModel` should be, negative twice the log-likelihood is called the `objective`.</code></pre><p>@docs objective</p><pre><code class="language-none">This value is also accessible as the `deviance` but the user should bear in mind that this doesn&#39;t have all the properties of a deviance which is corrected for the saturated model.
For example, it is not necessarily non-negative.</code></pre><p>@example Main objective(fm1)</p><pre><code class="language-none"></code></pre><p>@example Main deviance(fm1)</p><pre><code class="language-none">
The value optimized when fitting a `GeneralizedLinearMixedModel` is the Laplace approximation to the deviance or an adaptive Gauss-Hermite evaluation.</code></pre><p>@docs MixedModels.deviance!</p><pre><code class="language-none"></code></pre><p>@example Main MixedModels.deviance!(gm1)</p><pre><code class="language-none">
## Fixed-effects parameter estimates

The `coef` and `fixef` extractors both return the maximum likelihood estimates of the fixed-effects coefficients.
They differ in their behavior in the rank-deficient case.
The associated `coefnames` and `fixefnames` return the corresponding coefficient names.</code></pre><p>@docs coef coefnames fixef fixefnames</p><pre><code class="language-none"></code></pre><p>@example Main coef(fm1) coefnames(fm1)</p><pre><code class="language-none"></code></pre><p>@example Main fixef(fm1) fixefnames(fm1)</p><pre><code class="language-none">
An alternative extractor for the fixed-effects coefficient is the `β` property.
Properties whose names are Greek letters usually have an alternative spelling, which is the name of the Greek letter.</code></pre><p>@example Main fm1.β</p><pre><code class="language-none"></code></pre><p>@example Main fm1.beta</p><pre><code class="language-none"></code></pre><p>@example Main gm1.β</p><pre><code class="language-none">A full list of property names is returned by `propertynames`</code></pre><p>@example Main propertynames(fm1)</p><pre><code class="language-none"></code></pre><p>@example Main propertynames(gm1)</p><pre><code class="language-none">
The variance-covariance matrix of the fixed-effects coefficients is returned by</code></pre><p>@docs vcov</p><pre><code class="language-none"></code></pre><p>@example Main vcov(fm2)</p><pre><code class="language-none"></code></pre><p>@example Main vcov(gm1)</p><pre><code class="language-none">
The standard errors are the square roots of the diagonal elements of the estimated variance-covariance matrix of the fixed-effects coefficient estimators.</code></pre><p>@docs stderror</p><pre><code class="language-none"></code></pre><p>@example Main stderror(fm2)</p><pre><code class="language-none"></code></pre><p>@example Main stderror(gm1)</p><pre><code class="language-none">
Finally, the `coeftable` generic produces a table of coefficient estimates, their standard errors, and their ratio.
The *p-values* quoted here should be regarded as approximations.</code></pre><p>@docs coeftable</p><pre><code class="language-none"></code></pre><p>@example Main coeftable(fm2)</p><pre><code class="language-none">
## Covariance parameter estimates

The covariance parameters estimates, in the form shown in the model summary, are a `VarCorr` object</code></pre><p>@docs VarCorr</p><pre><code class="language-none"></code></pre><p>@example Main VarCorr(fm2)</p><pre><code class="language-none"></code></pre><p>@example Main VarCorr(gm1)</p><pre><code class="language-none">
Individual components are returned by other extractors</code></pre><p>@docs varest sdest</p><pre><code class="language-none"></code></pre><p>@example Main varest(fm2)</p><pre><code class="language-none"></code></pre><p>@example Main sdest(fm2)</p><pre><code class="language-none"></code></pre><p>@example Main fm2.σ</p><pre><code class="language-none">
## Conditional modes of the random effects

The `ranef` extractor</code></pre><p>@docs ranef</p><pre><code class="language-none"></code></pre><p>@example Main ranef(fm1)</p><pre><code class="language-none"></code></pre><p>@example Main fm1.b</p><pre><code class="language-none">returns the *conditional modes* of the random effects given the observed data.
That is, these are the values that maximize the conditional density of the random effects given the observed data.
For a `LinearMixedModel` these are also the conditional mean values.

These are sometimes called the *best linear unbiased predictors* or [`BLUPs`](https://en.wikipedia.org/wiki/Best_linear_unbiased_prediction) but that name is not particularly meaningful.

At a superficial level these can be considered as the &quot;estimates&quot; of the random effects, with a bit of hand waving, but pursuing this analogy too far usually results in confusion.

To obtain tables associating the values of the conditional modes with the levels of the grouping factor, use</code></pre><p>@docs raneftables</p><pre><code class="language-none">as in</code></pre><p>@example Main DataFrame(only(raneftables(fm1)))</p><pre><code class="language-none">
The corresponding conditional variances are returned by</code></pre><p>@docs condVar</p><pre><code class="language-none"></code></pre><p>@example Main condVar(fm1)</p><pre><code class="language-none">
## Case-wise diagnostics and residual degrees of freedom

The `leverage` values</code></pre><p>@docs leverage</p><pre><code class="language-none"></code></pre><p>@example Main leverage(fm1)</p><pre><code class="language-none">are used in diagnostics for linear regression models to determine cases that exert a strong influence on their own predicted response.

The documentation refers to a &quot;projection&quot;.
For a linear model without random effects the fitted values are obtained by orthogonal projection of the response onto the column span of the model matrix and the sum of the leverage values is the dimension of this column span.
That is, the sum of the leverage values is the rank of the model matrix and `n - sum(leverage(m))` is the degrees of freedom for residuals.
The sum of the leverage values is also the trace of the so-called &quot;hat&quot; matrix, `H`.
(The name &quot;hat matrix&quot; reflects the fact that $\hat{\mathbf{y}} = \mathbf{H} \mathbf{y}$.  That is, `H` puts a hat on `y`.)

For a linear mixed model the sum of the leverage values will be between `p`, the rank of the fixed-effects model matrix, and `p + q` where `q` is the total number of random effects.
This number does not represent a dimension (or &quot;degrees of freedom&quot;) of a linear subspace of all possible fitted values because the projection is not an orthogonal projection.
Nevertheless, it is a reasonable measure of the effective degrees of freedom of the model and `n - sum(leverage(m))` can be considered the effective residual degrees of freedom.

For model `fm1` the dimensions are</code></pre><p>@example Main n, p, q, k = size(fm1)</p><pre><code class="language-none">which implies that the sum of the leverage values should be in the range [1, 7].
The actual value is</code></pre><p>@example Main sum(leverage(fm1))</p><pre><code class="language-none">
For model `fm2` the dimensions are</code></pre><p>@example Main n, p, q, k = size(fm2)</p><pre><code class="language-none">providing a range of [2, 38] for the effective degrees of freedom for the model.
The observed value is</code></pre><p>@example Main sum(leverage(fm2))</p><pre><code class="language-none">
When a model converges to a singular covariance, such as</code></pre><p>@example Main fm3 = fit(MixedModel, @formula(yield ~ 1+(1|batch)), MixedModels.dataset(:dyestuff2))</p><pre><code class="language-none">the effective degrees of freedom is the lower bound.</code></pre><p>@example Main sum(leverage(fm3))</p><pre><code class="language-none">
Models for which the estimates of the variances of the random effects are large relative to the residual variance have effective degrees of freedom close to the upper bound.</code></pre><p>@example Main fm4 = fit(MixedModel, @formula(diameter ~ 1+(1|plate)+(1|sample)),     MixedModels.dataset(:penicillin))</p><pre><code class="language-none"></code></pre><p>@example Main sum(leverage(fm4))</p><pre><code class="language-none">
Also, a model fit by the REML criterion generally has larger estimates of the variance components and hence a larger effective degrees of freedom.</code></pre><p>@example Main fm4r = fit(MixedModel, @formula(diameter ~ 1+(1|plate)+(1|sample)),     MixedModels.dataset(:penicillin), REML=true)</p><pre><code class="language-none"></code></pre><p>@example Main sum(leverage(fm4r)) ```</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« MixedModels.jl Documentation</a><a class="docs-footer-nextpage" href="../optimization/">Details of the parameter estimation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Thursday 22 October 2020 12:51">Thursday 22 October 2020</span>. Using Julia version 1.5.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
