<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Rank deficiency in mixed-effects models · MixedModels</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="MixedModels logo"/></a><div class="docs-package-name"><span class="docs-autofit">MixedModels</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">MixedModels.jl Documentation</a></li><li><a class="tocitem" href="../constructors/">Model constructors</a></li><li><a class="tocitem" href="../optimization/">Details of the parameter estimation</a></li><li><a class="tocitem" href="../GaussHermite/">Normalized Gauss-Hermite Quadrature</a></li><li><a class="tocitem" href="../bootstrap/">Parametric bootstrap for linear mixed-effects models</a></li><li class="is-active"><a class="tocitem" href>Rank deficiency in mixed-effects models</a><ul class="internal"><li><a class="tocitem" href="#Fixed-effects-1"><span>Fixed effects</span></a></li><li><a class="tocitem" href="#Random-effects-1"><span>Random effects</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Rank deficiency in mixed-effects models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Rank deficiency in mixed-effects models</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaStats/MixedModels.jl/blob/master/docs/src/rankdeficiency.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Rank-deficiency-in-mixed-effects-models-1"><a class="docs-heading-anchor" href="#Rank-deficiency-in-mixed-effects-models-1">Rank deficiency in mixed-effects models</a><a class="docs-heading-anchor-permalink" href="#Rank-deficiency-in-mixed-effects-models-1" title="Permalink"></a></h1><p>The <em>(column) rank</em> of a matrix refers to the number of independent columns in the matrix. Clearly, the rank can never be more than the number of columns; however, the rank can be less than the number of columns. In a regression context, this corresponds to (linear) independency of the predictors. The simplest case of rank deficiency is a duplicated predictor or a predictor that is exactly a multiple of another predictor. However, rank deficiency can also arise from missing cells in the experimental design, in which case all values of the corresponding contrast/predictor are constant. Rank deficiency may also arise as an extreme case of multicollinearity. In all cases, it is important to remember that rank deficiency may arise numerically, even where it does not occur exactly.</p><p>Rank deficiency can occur in two ways in mixed-effects models: in the fixed effects and in the random effects. The implications of rank deficiency and thus the handling of of it differ between these.</p><h2 id="Fixed-effects-1"><a class="docs-heading-anchor" href="#Fixed-effects-1">Fixed effects</a><a class="docs-heading-anchor-permalink" href="#Fixed-effects-1" title="Permalink"></a></h2><p>Rank deficiency in the fixed effects works much the same way as it does in classical ordinary least squares regression. If one or more predictors can be expressed as a linear combination of the other columns, then this column is redudant and matrix is rank deficient. Note however, that the redudant column is not defined uniquely. For example, in the case that of two columns <code>a</code> and <code>b</code> where <code>b = 2a</code>, then the rank deficiency can be solved by eliminating <code>a</code> or <code>b</code>. While we defined <code>b</code> here in terms of <code>a</code>, it may be that <code>b</code> is actually the more &#39;fundamental&#39; predictor it is <code>a</code> that is defined in terms of <code>b</code>: <code>a = 0.5b</code>. The user may of course possess this information, but this is not apparent to modelling software. As such, the handling of rank deficiency in <code>MixedModels.jl</code> should not be taken as a replacement for thinking about the nature of the predictors in a given model.</p><p>There is a widely accepted convention for how to make the coefficient estimates for these redudant columns well-defined: we set their value to zero and their standard errors to <code>NaN</code> (and thus also their <span>$z$</span> and <span>$p$</span>-values). In practice this is done via &#39;pivoting&#39;: the effective rank of the model matrix determined and the extra columnns are moved to the end (right side) of the matrix. In subsequent calculations, these columns are effectively ignored (as their estimates are zero and thus won&#39;t contribute to any other computations). For display purposes, this pivoting is unwound at the end and the zeroed estimates are displayed in the output.</p><p>Both the pivoted and unpivoted coefficients are available in MixedModels. The <a href="../constructors/#MixedModels.fixef"><code>fixef</code></a> extractor returns the pivoted, truncated estimates (i.e. the non redudant terms), while the <a href="../constructors/#StatsBase.coef"><code>coef</code></a> extractor returns the unpivoted estimates (i.e. all terms, included the redudant ones). The same holds for the associated <a href="../constructors/#MixedModels.fixefnames"><code>fixefnames</code></a> and <a href="../constructors/#StatsBase.coefnames"><code>coefnames</code></a>.</p><h3 id="Pivoting-is-platform-dependent-1"><a class="docs-heading-anchor" href="#Pivoting-is-platform-dependent-1">Pivoting is platform dependent</a><a class="docs-heading-anchor-permalink" href="#Pivoting-is-platform-dependent-1" title="Permalink"></a></h3><p>In MixedModels.jl, we use standard numerical techniques to detect rank eficiency. We currently offer no guarantees as to which exactly of the standard techniques (e.g. pivoted QR decomposition, pivoted Cholesky decomposition). This should instead be viewed as an implementation detail. Similarly, we offer no guarentees as to which of columns will be treated as redudant. This may vary between releases and even between platforms (both in broad strokes &quot;Linux&quot; vs. &quot;Windows&quot; and at the level of which BLAS options are loaded on a given processor architecture) for the same release. In other words, <em>you should not rely on the pivoted columns being consistent!</em> If consistency in the pivoted columns is important to you, then you should instead determine your rank ahead of time and remove extraneous columns / predictors from your model specification.</p><p>This lack of consistency guarantees arises from a more fundamental issue: numeric linear algebra is challenging and sensitive to the underlying floating point operations. Due to rounding error, floating point arithmetic is not associative:</p><pre><code class="language-julia">0.1 + 0.1 + 0.1 - 0.3 == 0.1 + 0.1 + (0.1 - 0.3)</code></pre><pre><code class="language-none">false</code></pre><p>This means that &quot;nearly&quot; / numerically rank deficient matrices may or may not be detected as rank deficient, depending on details of the platform.</p><p>Currently, a coarse heuristic is applied to reduce the chance that the intercept column will be pivoted, but even this behavior is not guaranteed.</p><h2 id="Random-effects-1"><a class="docs-heading-anchor" href="#Random-effects-1">Random effects</a><a class="docs-heading-anchor-permalink" href="#Random-effects-1" title="Permalink"></a></h2><p>Rank deficiency presents less of a problem in the random effects than in the fixed effects. The same shrinkage that moves the conditional modes (group-level predictons) towards the grand mean is more generally a form of <em>regularization</em>. With regularization, we are able to find unique estimates for overparameterized models. (For more reading on this general idea, see also this <a href="https://jakevdp.github.io/blog/2015/07/06/model-complexity-myth/">blog post</a> on the model complexity myth.) In fact, this rank deficiency occurs in the case of a &quot;singular&quot; or &quot;boundary&quot; fit, where one or more of the variance components is estimated to be zero or a correlation is estimated to be exactly ±1 (i.e. a parameter is estimated to be at the boundary.) (Formally, a singular matrix has no multiplicative inverse, but a matrix is singular if and only if it is rank deficient and this corresponds to the value of one of the random-effects parameters being on the boundary of the parameter space.)</p><p>In addition to handling naturally occuring rank deficiency in the random effects, we can also use regularization to fit explicitly overparameterized random effects. For example, we can use <code>fulldummy</code> to fit both an intercept term and <span>$n$</span> indicator variables in the random effects for a categorical variable with <span>$n$</span> levels instead of the usual <span>$n-1$</span> contrasts.</p><pre><code class="language-julia">kb07 = MixedModels.dataset(:kb07)
contrasts = Dict(var =&gt; HelmertCoding() for var in (:spkr, :prec, :load))
fit(MixedModel, @formula(rt_raw ~ spkr * prec * load + (1|subj) + (1+prec|item)), kb07; contrasts=contrasts)</code></pre><pre><code class="language-none">Linear mixed model fit by maximum likelihood
 rt_raw ~ 1 + spkr + prec + load + spkr &amp; prec + spkr &amp; load + prec &amp; load + spkr &amp; prec &amp; load + (1 | subj) + (1 + prec | item)
   logLik    -2 logLik      AIC         BIC     
 -14846.7248  29693.4496  29719.4496  29790.8120

Variance components:
             Column        Variance    Std.Dev.  Corr.
item     (Intercept)     158695.3053735 398.366
         prec: maintain   93637.3461201 306.002 -0.81
subj     (Intercept)     105909.6205371 325.438
Residual                 842822.9064170 918.054
 Number of obs: 1789; levels of grouping factors: 32, 56

  Fixed-effects parameters:
──────────────────────────────────────────────────────────────────────────────
                                            Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────────────────────────────────
(Intercept)                             2225.71       85.5665  26.01    &lt;1e-99
spkr: old                                 74.1916     21.7062   3.42    0.0006
prec: maintain                          -377.212      58.2866  -6.47    &lt;1e-10
load: yes                                101.958      21.7062   4.70    &lt;1e-5
spkr: old &amp; prec: maintain               -28.0275     21.7062  -1.29    0.1966
spkr: old &amp; load: yes                     26.8642     21.7062   1.24    0.2159
prec: maintain &amp; load: yes               -18.6514     21.7062  -0.86    0.3902
spkr: old &amp; prec: maintain &amp; load: yes    15.4985     21.7062   0.71    0.4752
──────────────────────────────────────────────────────────────────────────────</code></pre><pre><code class="language-julia">fit(MixedModel, @formula(rt_raw ~ spkr * prec * load + (1|subj) + (1+fulldummy(prec)|item)), kb07; contrasts=contrasts)</code></pre><pre><code class="language-none">Linear mixed model fit by maximum likelihood
 rt_raw ~ 1 + spkr + prec + load + spkr &amp; prec + spkr &amp; load + prec &amp; load + spkr &amp; prec &amp; load + (1 | subj) + (1 + prec | item)
   logLik    -2 logLik      AIC         BIC     
 -14846.7248  29693.4496  29725.4496  29813.2802

Variance components:
             Column         Variance    Std.Dev.   Corr.
item     (Intercept)     1225798.5123980 1107.158
         prec: break      493552.8570616  702.533 -0.82
         prec: maintain  1006118.5513893 1003.055 -0.98 +0.80
subj     (Intercept)      105911.8633785  325.441
Residual                  842822.3203798  918.054
 Number of obs: 1789; levels of grouping factors: 32, 56

  Fixed-effects parameters:
──────────────────────────────────────────────────────────────────────────────
                                            Coef.  Std. Error      z  Pr(&gt;|z|)
──────────────────────────────────────────────────────────────────────────────
(Intercept)                             2225.71       85.567   26.01    &lt;1e-99
spkr: old                                 74.1916     21.7062   3.42    0.0006
prec: maintain                          -377.212      58.287   -6.47    &lt;1e-10
load: yes                                101.958      21.7062   4.70    &lt;1e-5
spkr: old &amp; prec: maintain               -28.0275     21.7062  -1.29    0.1966
spkr: old &amp; load: yes                     26.8642     21.7062   1.24    0.2159
prec: maintain &amp; load: yes               -18.6514     21.7062  -0.86    0.3902
spkr: old &amp; prec: maintain &amp; load: yes    15.4985     21.7062   0.71    0.4752
──────────────────────────────────────────────────────────────────────────────</code></pre><p>This may be useful when rePCA suggests a random effects structure larger than merely main effects but smaller than all interaction terms. This is also simiar to the functionality provided by <code>dummy</code> in <code>lme4</code>, but as in the difference between <code>zerocorr</code> in Julia and <code>||</code> in R, there are subtle differences in how this explansion interacts with other terms in the random effects.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../bootstrap/">« Parametric bootstrap for linear mixed-effects models</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 14 September 2020 20:40">Monday 14 September 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
